{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNI13CS3lSufUPN4YSNPKZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bismark021/Bisfun/blob/main/Copy_of_Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-x5yWxd-zFL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G1d-vajDD7D",
        "outputId": "c193e3ca-a50a-4b4e-f97e-1e53b10fe7ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-nWR7ALDVMC",
        "outputId": "9a38cba1-ccf9-4d00-b30d-9189914069ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 15792, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 15792 (delta 15), reused 27 (delta 8), pack-reused 15743 (from 1)\u001b[K\n",
            "Receiving objects: 100% (15792/15792), 6.37 MiB | 11.65 MiB/s, done.\n",
            "Resolving deltas: 100% (11507/11507), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd detectron2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yl1iLfLDXeg",
        "outputId": "296fe7e7-26fe-473d-dcbb-00f184aa6874"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/detectron2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z_knngHqDbm8",
        "outputId": "e8196417-97fe-48f0-b987-c74cfe348ecf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/detectron2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (10.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.5.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.1.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.17.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=5d78e12cc2e92ce7c7bdc27712260dfa997c776f38e2ef6ad8f7d7f96e356526\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=4ec835c8fdcc570977416217c2000a680532e499ab04e50dcedd63ab22b1da32\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "  Running setup.py develop for detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-24.10.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.10.1 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "21cc0579342242c39e2eabba8cebdd93"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json,cv2, random\n",
        "#import matplotlib.pyplot as plt\n",
        "import skimage.io as io\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def pred_price(image_path):\n",
        "\n",
        "    def DICE_COE(mask1, mask2):\n",
        "        intersect = np.sum(mask1*mask2)\n",
        "        fsum = np.sum(mask1)\n",
        "        ssum = np.sum(mask2)\n",
        "        dice = (2 * intersect ) / (fsum + ssum)\n",
        "        dice = np.mean(dice)\n",
        "        #dice = round(dice, 3) # for easy reading\n",
        "        return dice"
      ],
      "metadata": {
        "id": "jXk64mDRDJzr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n"
      ],
      "metadata": {
        "id": "71iyJ7-KMLyR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"drive/MyDrive/path_to_your_model/model_final_1.pth\"\n"
      ],
      "metadata": {
        "id": "SZ9vCxrlPBm0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/PROJO\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "save_path = os.path.join(save_dir, \"model_final_1.pth\")\n"
      ],
      "metadata": {
        "id": "Rs3OzM7rPQCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.hub.download_url_to_file(cfg.MODEL.WEIGHTS, save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkvpa5-6Pxa8",
        "outputId": "3bfc45a7-0522-4617-9543-717dfd4a77e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 171MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "# Set the save directory\n",
        "save_dir = \"/content/drive/MyDrive/PROJO\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Define the model URL\n",
        "model_url = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "# Download and save the model weights to Google Drive\n",
        "save_path = os.path.join(save_dir, \"model_final_1.pth\")\n",
        "torch.hub.download_url_to_file(model_url, save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ1HTj32RErc",
        "outputId": "c0e5f468-529a-4518-afa6-52f9252bb970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:00<00:00, 181MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = save_path  # Update the path to the newly downloaded file\n"
      ],
      "metadata": {
        "id": "dtkkN91cRm6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "# Set the save directory\n",
        "save_dir = \"/content/drive/MyDrive/PROJO\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Define the model URL\n",
        "model_url = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "# Download and save the model weights to Google Drive\n",
        "save_path = os.path.join(save_dir, \"model_final_1.pth\")\n",
        "\n",
        "# Ensure previous file is removed\n",
        "if os.path.exists(save_path):\n",
        "    os.remove(save_path)\n",
        "\n",
        "# Download the file\n",
        "torch.hub.download_url_to_file(model_url, save_path)\n"
      ],
      "metadata": {
        "id": "ry9r5UhRRzCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43dcaf56-c5eb-423b-cf44-fe7ebd926b28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 144MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im = cv2.imread(\"/content/drive/MyDrive/39.jpg\")"
      ],
      "metadata": {
        "id": "lBgj_UOYuh42"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor1 = DefaultPredictor(cfg)\n",
        "outputs = predictor(im)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSBux0VhtK06",
        "outputId": "e5561c64-d15e-4206-b6c9-16189d23c339"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10/29 10:04:33 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from PIL import Image\n",
        "import skimage.io as io\n",
        "\n",
        "# Set metadata using Detectron2's MetadataCatalog\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# Register metadata if not done already (replace 'damage_type' with your dataset name if needed)\n",
        "damage_metadata = MetadataCatalog.get(\"damage_type_train\")\n",
        "damage_metadata.set(thing_classes=['minor', 'moderate', 'severe'])\n",
        "\n",
        "# Load the image\n",
        "image_path = '/content/drive/MyDrive/39.jpg'  # Ensure this path is correct and file exists\n",
        "im = io.imread(image_path)\n",
        "\n",
        "# Run prediction\n",
        "outputs = predictor1(im)\n",
        "\n",
        "# Visualize\n",
        "v = Visualizer(im[:, :, ::-1],\n",
        "               metadata=damage_metadata,  # Use the metadata registered in Detectron2\n",
        "               scale=0.5)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "# Convert to image and save\n",
        "ima = Image.fromarray(out.get_image()[:, :, ::-1])\n",
        "\n",
        "# Ensure save directory exists\n",
        "save_dir = 'static'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save the image with a new filename\n",
        "save_path = os.path.join(save_dir, 'predicted_image.jpg')\n",
        "ima.save(save_path)\n",
        "\n",
        "print(f\"Saved prediction image to: {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr0om1-0uxx6",
        "outputId": "d640696f-e539-403f-ea84-0bc2f9723a4b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved prediction image to: static/predicted_image.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_2 = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg_2.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg_2.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg_2.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor2 = DefaultPredictor(cfg)\n",
        "outputs = predictor2(im)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "244g5WMmyk6k",
        "outputId": "de42e5f2-3909-48d2-f9d2-3c72b38ba2cf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10/29 10:27:00 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_2 = get_cfg()\n",
        "cfg_2.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg_2.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg_2.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # faster, and good enough for this  dataset (default: 512)\n",
        "cfg_2.MODEL.ROI_HEADS.NUM_CLASSES = 5  # only has one class (damage)\n",
        "cfg_2.MODEL.RETINANET.NUM_CLASSES = 5 # only has one class (damage)\n",
        "\n",
        "cfg_2.MODEL.DEVICE = \"cuda\"\n",
        "\n",
        "cfg_2.MODEL.WEIGHTS = os.path.join('models', \"model_final_2.pth\")\n",
        "cfg_2.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.70  # set a custom testing threshold for this model\n",
        "    #cfg.DATASETS.TEST = (\"car_part_val\")\n",
        "predictor2 = DefaultPredictor(cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-ePNbEixBXy",
        "outputId": "bfdcc6de-fa1b-44df-abd7-8da27047d6bb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10/29 10:28:01 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_2.MODEL.WEIGHTS = \"/content/drive/MyDrive/PROJO/model_final_2.pth\""
      ],
      "metadata": {
        "id": "LVDoTcHXyRSU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/PROJO\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "save_path = os.path.join(save_dir, \"model_final_2.pth\")"
      ],
      "metadata": {
        "id": "HmzEdPcKz2ot"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "83C7rJatyQ-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the path (change the path to where your file is located)\n",
        "repair_cost = '/content/drive/MyDrive/Train data/9bc6b2378db97102de23cc86354e4f63-37fb0d63cfd98f4643cbf951a5df946abca0796b/train_data.csv'\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(repair_cost)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i24_2Il73nmt",
        "outputId": "712bd14a-bd42-4260-b0ce-0fec59adb4ab"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   headlamp_dice  rear_bump_dice  \\tdoor_dice  \\thood_dice  \\tfront_bump_dice  \\\n",
            "0            0.0        0.000000      0.00460          0.0                0.0   \n",
            "1            0.0        0.000000      0.00241          0.0                0.0   \n",
            "2            0.0        0.041677      0.00000          0.0                0.0   \n",
            "3            0.0        0.026820      0.00000          0.0                0.0   \n",
            "4            0.0        0.000000      0.00000          0.0                0.0   \n",
            "\n",
            "    unknown  \\tminor  \\tmoderate  \\tsevere  \\tprice  \n",
            "0         0        0           1         0      500  \n",
            "1         0        0           1         0       50  \n",
            "2         0        1           0         0      400  \n",
            "3         0        1           0         0      400  \n",
            "4         1        0           1         0      250  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict = {'headlamp_dice':[],'rear_bumper_dice':[],'door_dice':[],'hood_dice':[],'front_bumper_dice':[],'minor':[],'moderate':[],'severe':[]}\n",
        "\n",
        "damage_categories = ['minor','moderate','severe']\n",
        "part_categories = ['headlamp','rear_bumper','door','hood','front_bumper']\n",
        "    #coco = COCO(val_json)\n",
        "    #image_ids = np.arange(11)\n",
        "img = io.imread(image_path)\n",
        "damage_type_outputs = predictor1(img)\n",
        "car_part_outputs = predictor2(img)\n",
        "\n",
        "cat_ids1 = [0,1,2]\n",
        "anns = damage_type_outputs['instances'].pred_masks.cpu().numpy()\n",
        "\n",
        "cat_ids2 = [0,1,2,3,4]\n",
        "anns2 = car_part_outputs['instances'].pred_masks.cpu().numpy()"
      ],
      "metadata": {
        "id": "MGYubeF14fIb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def DICE_COE(mask1, mask2):\n",
        "    # Flatten the masks to make sure they're 1D arrays\n",
        "    mask1 = mask1.flatten()\n",
        "    mask2 = mask2.flatten()\n",
        "\n",
        "    # Calculate the intersection and union\n",
        "    intersection = np.sum(mask1 * mask2)\n",
        "    sum_masks = np.sum(mask1) + np.sum(mask2)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if sum_masks == 0:\n",
        "        return 1.0  # or 0.0 if you prefer to handle empty masks differently\n",
        "\n",
        "    # Compute the Dice coefficient\n",
        "    dice_coefficient = 2 * intersection / sum_masks\n",
        "    return dice_coefficient\n"
      ],
      "metadata": {
        "id": "RqQk2Z_C6oCY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global headlamp_dice\n",
        "global rear_bumper_dice\n",
        "global door_dice\n",
        "global hood_dice\n",
        "global front_bumper_dice\n",
        "\n",
        "for j in range(len(anns)):\n",
        "\n",
        "\n",
        " headlamp_dice = 0\n",
        " rear_bumper_dice = 0\n",
        " door_dice = 0\n",
        " hood_dice = 0\n",
        " front_bumper_dice = 0\n",
        " cats = []\n",
        "\n",
        " mask1 = anns[j]\n",
        "\n",
        "\n",
        "for k in range(len(anns2)):\n",
        "            mask2 = anns2[k]\n",
        "            dice_coe = DICE_COE(mask1,mask2)\n",
        "            part_category_id = int(car_part_outputs['instances'].pred_classes[k])\n",
        "            part_affected = part_categories[part_category_id]\n",
        "            cats.append(int(car_part_outputs['instances'].pred_classes[k]))\n",
        "            globals()[part_affected+'_dice'] += dice_coe\n",
        "\n",
        "for k in cat_ids2:\n",
        "            part_name = part_categories[k]\n",
        "            dict[part_name+'_dice'].append(globals()[part_name+'_dice'])\n",
        "\n",
        "damage_type = damage_categories[int(damage_type_outputs['instances'].pred_classes[j])]\n",
        "dict[damage_type].append(1)\n",
        "\n",
        "for k in cat_ids1:\n",
        "            if k != int(damage_type_outputs['instances'].pred_classes[j]):\n",
        "                damage_type = damage_categories[k]\n",
        "                dict[damage_type].append(0)"
      ],
      "metadata": {
        "id": "1ekEUV7l4v_j"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repair_cost = pd.DataFrame(dict)\n",
        "unknown = []\n",
        "for i in val_repair_cost_dataset.iloc:\n",
        "        if i['headlamp_dice'] == i['rear_bumper_dice'] == i['door_dice'] == i['hood_dice'] == i['front_bumper_dice'] == 0:\n",
        "            unknown.append(1)\n",
        "        else:\n",
        "            unknown.append(0)\n",
        "\n",
        "repair_cost.insert(loc=5, column='unknown', value=unknown)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "GchjOsPB6t0L",
        "outputId": "fb45e683-6200-4f3e-f953-7ffc7315fa23"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "All arrays must be of the same length",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-a3fcfd439016>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrepair_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0munknown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_repair_cost_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headlamp_dice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rear_bumper_dice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'door_dice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hood_dice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'front_bumper_dice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0munknown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unknown = []\n",
        "for i in val_repair_cost_dataset.iloc:\n",
        "        if i['headlamp_dice'] == i['rear_bumper_dice'] == i['door_dice'] == i['hood_dice'] == i['front_bumper_dice'] == 0:\n",
        "            unknown.append(1)\n",
        "        else:\n",
        "            unknown.append(0)\n",
        "\n",
        "val_repair_cost_dataset.insert(loc=5, column='unknown', value=unknown)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "O8ddPrR-6txi",
        "outputId": "7a1af0f4-80bc-4a15-9123-dadab7a7a147"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'val_repair_cost_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-231e1df74923>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munknown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_repair_cost_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headlamp_dice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rear_bumper_dice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'door_dice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hood_dice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'front_bumper_dice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0munknown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_repair_cost_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check lengths of all lists in your dictionary\n",
        "for key, value in dict.items():\n",
        "    print(f\"{key}: {len(value)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED2_s7kICGgp",
        "outputId": "c06fb8eb-d8e5-4fff-945f-c46c400c4588"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "headlamp_dice: 2\n",
            "rear_bumper_dice: 2\n",
            "door_dice: 2\n",
            "hood_dice: 2\n",
            "front_bumper_dice: 2\n",
            "minor: 1\n",
            "moderate: 1\n",
            "severe: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Original dictionary\n",
        "data = {\n",
        "    'headlamp_dice': 2,\n",
        "    'rear_bumper_dice': 2,\n",
        "    'door_dice': 2,\n",
        "    'hood_dice': 2,\n",
        "    'front_bumper_dice': 2,\n",
        "    'minor': 1,\n",
        "    'moderate': 1,\n",
        "    'severe': 2\n",
        "}\n",
        "\n",
        "# Convert each value to a list\n",
        "# Here we convert to lists with the same length, e.g., length of 2 for all\n",
        "max_length = 2\n",
        "for key in data:\n",
        "    data[key] = [data[key]] * max_length\n",
        "\n",
        "# Convert to DataFrame\n",
        "repair_cost = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(repair_cost)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_4gb7YzCGcL",
        "outputId": "d6a98226-1111-443b-923b-e548a92a5a0a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   headlamp_dice  rear_bumper_dice  door_dice  hood_dice  front_bumper_dice  \\\n",
            "0              2                 2          2          2                  2   \n",
            "1              2                 2          2          2                  2   \n",
            "\n",
            "   minor  moderate  severe  \n",
            "0      1         1       2  \n",
            "1      1         1       2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unknown = []\n",
        "for i in repair_cost.iloc:\n",
        "        if i['headlamp_dice'] == i['rear_bumper_dice'] == i['door_dice'] == i['hood_dice'] == i['front_bumper_dice'] == 0:\n",
        "            unknown.append(1)\n",
        "        else:\n",
        "            unknown.append(0)\n",
        "\n",
        "repair_cost.insert(loc=5, column='unknown', value=unknown)"
      ],
      "metadata": {
        "id": "buWRUwMMCm5N"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate total_price\n",
        "\n",
        "operatorlookup = {\n",
        "        '+': operator.add,\n",
        "        '-': operator.sub,\n",
        "        '==': operator.eq,\n",
        "        '>': operator.gt\n",
        "    }\n",
        "\n",
        "total_price = 0\n",
        "\n",
        "for i in val_repair_cost_dataset.iloc:\n",
        "\n",
        "        d = i.to_dict()\n",
        "\n",
        "        a = []\n",
        "        opt = []\n",
        "        for i in d.values():\n",
        "            if i > 0 and i!=1:\n",
        "                a.append(0)\n",
        "                opt.append('>')\n",
        "            elif i == 1:\n",
        "                a.append(1)\n",
        "                opt.append('==')\n",
        "            else:\n",
        "                a.append(0)\n",
        "                opt.append('==')\n",
        "\n",
        "        price = repair_cost_dataset[(operatorlookup[opt[0]](repair_cost_dataset[val_repair_cost_dataset.columns[0]], a[0])) &\n",
        "                            (operatorlookup[opt[1]](repair_cost_dataset[val_repair_cost_dataset.columns[1]], a[1])) &\n",
        "                            (operatorlookup[opt[2]](repair_cost_dataset[val_repair_cost_dataset.columns[2]], a[2])) &\n",
        "                            (operatorlookup[opt[3]](repair_cost_dataset[val_repair_cost_dataset.columns[3]], a[3])) &\n",
        "                            (operatorlookup[opt[4]](repair_cost_dataset[val_repair_cost_dataset.columns[4]], a[4])) &\n",
        "                            (operatorlookup[opt[5]](repair_cost_dataset[val_repair_cost_dataset.columns[5]], a[5])) &\n",
        "                            (operatorlookup[opt[6]](repair_cost_dataset[val_repair_cost_dataset.columns[6]], a[6])) &\n",
        "                            (operatorlookup[opt[7]](repair_cost_dataset[val_repair_cost_dataset.columns[7]], a[7])) &\n",
        "                            (operatorlookup[opt[8]](repair_cost_dataset[val_repair_cost_dataset.columns[8]], a[8]))].price.mean()\n",
        "\n",
        "        total_price += price\n",
        "\n",
        "return total_price, save_path\n",
        "\n",
        "\n",
        "if  __name__ == '__main__':\n",
        "    price,path = pred_price('static\\9.jpg')\n",
        "    print(price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "hjwpYXqOCzSC",
        "outputId": "633d3c68-c733-4abc-827d-02034c3b1239"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'val_repair_cost_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-d1b69915db96>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtotal_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_repair_cost_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_repair_cost_dataset' is not defined"
          ]
        }
      ]
    }
  ]
}